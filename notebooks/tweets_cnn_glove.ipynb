{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_cnn--glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiprGXm1pS2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZINcsSiGb5La",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "771cb4a7-1d85-4edc-ccd7-911e5f935338"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXjuDO-iExk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4c4e8ba4-0f5d-4623-f54b-7fbbb7233d5b"
      },
      "source": [
        "!pip install ndjson"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ndjson\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/03/7dce7f71bce783fae64015e74b123b5e26074e356401664051d6f2339e7c/ndjson-0.2.0-py2.py3-none-any.whl\n",
            "Installing collected packages: ndjson\n",
            "Successfully installed ndjson-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHV3dYucthVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ce242818-841b-498d-92b3-2a5b52556703"
      },
      "source": [
        "import ndjson\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import vectorize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "import nltk\n",
        "# packages settings\n",
        "nltk.data.path.append('./')\n",
        "nltk.download('stopwords', download_dir='./')\n",
        "nltk.download('punkt', download_dir='./')\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to ./...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to ./...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfAp21tVjiAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('french'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YP_TobtD1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadTweetsFromNDJson(filepath):\n",
        "    f = open(filepath)\n",
        "    content = f.read()\n",
        "    return ndjson.loads(content)\n",
        "\n",
        "def save(fileName, content):\n",
        "    f = open(fileName, 'w')\n",
        "    f.write(content)\n",
        "    f.close()\n",
        "    print(\"Wrote in {}\".format(fileName))\n",
        "\n",
        "def setSplitter(complete_dataset, train_quota, validation_quota, test_quota):\n",
        "    splitting_dataset = complete_dataset.copy()\n",
        "\n",
        "    relative_validation_quota = round(validation_quota / (1 - train_quota), 1)\n",
        "    relative_test_quota = round(test_quota / (1 - train_quota - validation_quota), 1)\n",
        "\n",
        "    train_data = splitting_dataset.sample(frac = validation_quota)\n",
        "\n",
        "    # remove training_data from splitting_dataset\n",
        "    splitting_dataset = splitting_dataset.drop(train_data.index)\n",
        "\n",
        "    validation_data = splitting_dataset.sample(frac=relative_validation_quota)\n",
        "\n",
        "    # remove validation_data from splitting_dataset\n",
        "    splitting_dataset = splitting_dataset.drop(validation_data.index)        \n",
        "\n",
        "    test_data = splitting_dataset.sample(frac=relative_test_quota)\n",
        "\n",
        "    return (train_data, validation_data, test_data)\n",
        "\n",
        "def toXY(dataframe_input):\n",
        "    X = ()\n",
        "    Y = ()\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    raw_Y = dataframe_input['polarity']\n",
        "    Y = lb.fit_transform(raw_Y)\n",
        "\n",
        "    print(lb.classes_)\n",
        "\n",
        "    X = dataframe_input.drop(columns=['polarity'])\n",
        "\n",
        "    return (X['encoded_message'].tolist(), Y)\n",
        "\n",
        "def loadGloVe(file_path):\n",
        "    embeddings_index = dict()\n",
        "    f = open(file_path, encoding='utf8')\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "    f.close()\n",
        "    print('Loaded %s word vectors' % len(embeddings_index))\n",
        "\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "def createWeightMatrix(vocab_size, tokenizer, embeddings_index):\n",
        "    embedding_matrix = zeros((vocab_size, 100))\n",
        "    \n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def removeStopWordsFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([item for item in word_tokenize(x) if item not in stop_words]))\n",
        "    return dataframe\n",
        "\n",
        "def removeVariousTwitterElementsFromMessage(dataframe):\n",
        "    regex_filter = \"(@[a-zA-ZÀ-ÿ0-9]+)|(#[a-zA-ZÀ-ÿ0-9]+)\"\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join(re.sub(regex_filter, ' ', x).split()))\n",
        "    return dataframe\n",
        "\n",
        "def removeUrlsFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: re.split('https?:\\/\\/.*', str(x))[0])\n",
        "    return dataframe\n",
        "\n",
        "def messageStemming(dataframe):\n",
        "    stemmer = FrenchStemmer()\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([stemmer.stem(y) for y in word_tokenize(x)]))\n",
        "    return dataframe\n",
        "\n",
        "def getOnlyAlphaFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.isalpha()]))\n",
        "    return dataframe\n",
        "\n",
        "def prepareDataframeMessage(dataframe_source):\n",
        "    df = dataframe_source.copy()\n",
        "    return (df\n",
        "            .pipe(removeUrlsFromMessage)\n",
        "            .pipe(removeVariousTwitterElementsFromMessage)\n",
        "            .pipe(getOnlyAlphaFromMessage)\n",
        "            .pipe(removeStopWordsFromMessage)\n",
        "            .pipe(messageStemming)\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHWCB7OHlh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "68527a9f-bedc-4ad1-8e3a-40e71ecaad75"
      },
      "source": [
        "# load tweets from json (ndjson)\n",
        "tweetsRecord = loadTweetsFromNDJson('./drive/My Drive/Cours/application_innovation/datasets/project_tp_annotated-hashtags-textblob.json')\n",
        "#tweetsRecord = loadTweetsFromNDJson('./project_svm_annotated.json')\n",
        "\n",
        "# load tweets in pandas dataframe\n",
        "tweetsDataframe = pd.DataFrame(tweetsRecord)\n",
        "# filter columns to use only message and polarity\n",
        "tweetsDataframe = tweetsDataframe[['message', 'polarity']]\n",
        "\n",
        "tweetsDataframe.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>75159</td>\n",
              "      <td>75159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>48321</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>\"En parlant constamment de similarité entre prog FN &amp; de la #FI , vous journalistes faites la campagne de M Lepen\" @RaquelGarridoFI #LeDebat</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>19</td>\n",
              "      <td>28374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                             message polarity\n",
              "count   75159                                                                                                                                         75159  \n",
              "unique  48321                                                                                                                                         4      \n",
              "top     \"En parlant constamment de similarité entre prog FN & de la #FI , vous journalistes faites la campagne de M Lepen\" @RaquelGarridoFI #LeDebat  positif\n",
              "freq    19                                                                                                                                            28374  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEw4NRNKBvav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f83bd288-bce0-49b5-da14-6162c655fd8a"
      },
      "source": [
        "tweetsDataframe = prepareDataframeMessage(tweetsDataframe)\n",
        "tweetsDataframe.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>suicid prémed peur pouvoir respons pen just cruch vid</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>autre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conclus journal madam lepen respect regl fix tout dit</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>là marin écroul comm merd</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>élect gross mascarad fait vieux mond a fait tout survivr</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    message polarity\n",
              "0  suicid prémed peur pouvoir respons pen just cruch vid     negatif\n",
              "1                                                            autre  \n",
              "2  conclus journal madam lepen respect regl fix tout dit     positif\n",
              "3  là marin écroul comm merd                                 negatif\n",
              "4  élect gross mascarad fait vieux mond a fait tout survivr  positif"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUHnrvpckaZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras text tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tweetsDataframe['message'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOufv8bx_EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "475ec96d-0d34-4877-e252-65207304f886"
      },
      "source": [
        "longest_message_length = tweetsDataframe.message.str.len().max()\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "labels_size = len(tweetsDataframe['polarity'].unique())\n",
        "print(\"Labels count : {}\".format(labels_size))\n",
        "print(\"Longest message length : {}\".format(longest_message_length))\n",
        "print(\"Vocabulary size : {}\".format(vocab_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels count : 4\n",
            "Longest message length : 114\n",
            "Vocabulary size : 16643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZ0wT4plCea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_messages_list = tokenizer.texts_to_sequences(tweetsDataframe['message'].tolist())\n",
        "padded_messages_list = pad_sequences(\n",
        "    encoded_messages_list, \n",
        "    maxlen=longest_message_length, \n",
        "    padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-az1GGllZol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9fa0da4-8d07-4066-e7b3-b0b292e55a55"
      },
      "source": [
        "embeddings_index = loadGloVe('./drive/My Drive/Cours/application_innovation/glove.6B.100d.txt')\n",
        "embeddings_matrix = createWeightMatrix(vocab_size, tokenizer, embeddings_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeDQykJrzC2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1ce8441c-83ce-4bf6-c3c4-a76b6575b589"
      },
      "source": [
        "# encode message column\n",
        "tweetsDataframe['encoded_message'] = array(padded_messages_list).tolist()\n",
        "\n",
        "tweetsDataframe = tweetsDataframe.drop(columns=['message'])\n",
        "\n",
        "tweetsDataframe.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>encoded_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negatif</td>\n",
              "      <td>[608, 10551, 138, 219, 501, 7, 71, 3995, 143, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>autre</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positif</td>\n",
              "      <td>[87, 81, 57, 3, 97, 543, 1696, 13, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negatif</td>\n",
              "      <td>[53, 6, 3996, 20, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positif</td>\n",
              "      <td>[279, 254, 1956, 10, 1092, 100, 2, 10, 13, 5518, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  polarity                                                                                                                                                                                                                                                                                                                      encoded_message\n",
              "0  negatif  [608, 10551, 138, 219, 501, 7, 71, 3995, 143, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "1  autre    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]                  \n",
              "2  positif  [87, 81, 57, 3, 97, 543, 1696, 13, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]       \n",
              "3  negatif  [53, 6, 3996, 20, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]            \n",
              "4  positif  [279, 254, 1956, 10, 1092, 100, 2, 10, 13, 5518, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjJXhz8LqA4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the set\n",
        "\n",
        "# 70% for training\n",
        "training_set_percentage = 0.7\n",
        "# 15% for validation\n",
        "validation_set_percentage = 0.15\n",
        "# 15% for evaluation\n",
        "evaluation_set_percentage = 0.15\n",
        "\n",
        "(training_set, validation_set, evaluation_set) = setSplitter(\n",
        "    tweetsDataframe, \n",
        "    training_set_percentage, \n",
        "    validation_set_percentage,\n",
        "    evaluation_set_percentage\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHu3UEKardOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47d6c3bd-559d-4526-907a-54d2093d7c3e"
      },
      "source": [
        "# Transform dataframe to X and Y values, to feed to the network\n",
        "(X_training_set, Y_training_set) = toXY(training_set)\n",
        "(X_validation_set, Y_validation_set) = toXY(validation_set)\n",
        "(x_evaluation_set, Y_evaluation_set) = toXY(evaluation_set)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['autre' 'mixte' 'negatif' 'positif']\n",
            "['autre' 'mixte' 'negatif' 'positif']\n",
            "['autre' 'mixte' 'negatif' 'positif']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyisBHrH6BZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_training_set = array(X_training_set)\n",
        "X_validation_set = array(X_validation_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP81FuJ6PMh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ModelCheckPoint configuration\n",
        "MODEL_SAVE_PATH = './sequential.hdf5'\n",
        "modelCheckpointCallback = ModelCheckpoint(\n",
        "    MODEL_SAVE_PATH,\n",
        "    monitor='val_categorical_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='max',\n",
        "    period=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zxnW2tRPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b9f62f55-06fe-48f9-f413-43a63892936d"
      },
      "source": [
        "# Define model\n",
        "# https://keras.io/examples/pretrained_word_embeddings/\n",
        "embedding_layer = Embedding(\n",
        "    vocab_size,\n",
        "    100,\n",
        "    input_length=longest_message_length,\n",
        "    embeddings_initializer=Constant(embeddings_matrix),\n",
        "    trainable=False\n",
        ")\n",
        "sequence_input = Input(shape=(longest_message_length,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 3, activation='relu')(embedded_sequences)\n",
        "x = MaxPooling1D(3)(x)\n",
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "x = MaxPooling1D(3)(x)\n",
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(labels_size, activation='softmax')(x)\n",
        "model = Model(sequence_input, preds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcQcNmpVueft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "721d359e-5059-451a-be34-a1a7c2bb4312"
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[categorical_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 114)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 114, 100)          1664300   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 112, 128)          38528     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 1,818,416\n",
            "Trainable params: 154,116\n",
            "Non-trainable params: 1,664,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEVs3JOtufi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "522e6369-3f7f-45c6-8460-d6aa37f4b57a"
      },
      "source": [
        "# fit the model\n",
        "model.fit(\n",
        "    X_training_set, \n",
        "    Y_training_set, \n",
        "    epochs=10, \n",
        "    verbose=1, \n",
        "    validation_data=(X_validation_set, Y_validation_set),\n",
        "    callbacks=[modelCheckpointCallback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 11274 samples, validate on 31942 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "11274/11274 [==============================] - 22s 2ms/step - loss: 1.0000 - categorical_accuracy: 0.5223 - val_loss: 0.9239 - val_categorical_accuracy: 0.5802\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.58018, saving model to ./sequential.hdf5\n",
            "Epoch 2/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.8220 - categorical_accuracy: 0.6408 - val_loss: 0.8728 - val_categorical_accuracy: 0.6195\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.58018 to 0.61950, saving model to ./sequential.hdf5\n",
            "Epoch 3/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.6908 - categorical_accuracy: 0.7185 - val_loss: 0.7619 - val_categorical_accuracy: 0.6875\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.61950 to 0.68753, saving model to ./sequential.hdf5\n",
            "Epoch 4/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.5809 - categorical_accuracy: 0.7761 - val_loss: 0.8441 - val_categorical_accuracy: 0.6859\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 5/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.4964 - categorical_accuracy: 0.8136 - val_loss: 1.1158 - val_categorical_accuracy: 0.6491\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 6/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.4314 - categorical_accuracy: 0.8456 - val_loss: 1.2290 - val_categorical_accuracy: 0.6277\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 7/10\n",
            "11274/11274 [==============================] - 21s 2ms/step - loss: 0.3789 - categorical_accuracy: 0.8653 - val_loss: 1.1127 - val_categorical_accuracy: 0.6846\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 8/10\n",
            "11274/11274 [==============================] - 22s 2ms/step - loss: 0.3477 - categorical_accuracy: 0.8780 - val_loss: 1.1945 - val_categorical_accuracy: 0.6739\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 9/10\n",
            "11274/11274 [==============================] - 22s 2ms/step - loss: 0.3348 - categorical_accuracy: 0.8821 - val_loss: 2.5979 - val_categorical_accuracy: 0.5878\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.68753\n",
            "Epoch 10/10\n",
            "11274/11274 [==============================] - 22s 2ms/step - loss: 0.3241 - categorical_accuracy: 0.8905 - val_loss: 1.4027 - val_categorical_accuracy: 0.6836\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy did not improve from 0.68753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe817e39f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsPfpTwPvFTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e0bfb7c4-155b-436e-cd5a-010b7f6ccc21"
      },
      "source": [
        "# evaluate the model\n",
        "best_model = load_model(MODEL_SAVE_PATH)\n",
        "loss, accuracy = best_model.evaluate(X_validation_set, Y_validation_set, verbose=1)\n",
        "print(\"Loss : {}\".format(loss))\n",
        "print(\"Accuracy : {}\".format(accuracy))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31942/31942 [==============================] - 11s 342us/step\n",
            "Loss : 0.761925192902154\n",
            "Accuracy : 0.6875273934042705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWCZR1WxqpFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0bd83122-f40c-4885-c3a7-7eb0f058b61b"
      },
      "source": [
        "# ----------------------\n",
        "# Predict on test data\n",
        "# ----------------------\n",
        "# --- Use same tokenizer than model\n",
        "\n",
        "# load tweets from json (ndjson)\n",
        "testTweetsRecord = loadTweetsFromNDJson('./drive/My Drive/Cours/application_innovation/datasets/test-euapv.json')\n",
        "\n",
        "# load tweets in pandas dataframe\n",
        "testDataframe = pd.DataFrame(testTweetsRecord)\n",
        "\n",
        "# filter columns to use only message\n",
        "testDataframe = testDataframe[['message']]\n",
        "\n",
        "print(testDataframe.describe())\n",
        "\n",
        "testDataframe = prepareDataframeMessage(testDataframe)\n",
        "\n",
        "# Encode messages using previously fitted tokenizer\n",
        "encoded_messages_list = tokenizer.texts_to_sequences(testDataframe['message'].tolist())\n",
        "padded_messages_list = pad_sequences(\n",
        "    encoded_messages_list, \n",
        "    maxlen=longest_message_length, \n",
        "    padding='post')\n",
        "\n",
        "# Set new column in dataframe with endoded date\n",
        "testDataframe['encoded_message'] = array(padded_messages_list).tolist()\n",
        "\n",
        "testDataframe = testDataframe.drop(columns=['message'])\n",
        "\n",
        "# Use encoded data from pandas dataframe\n",
        "X_predict = array(testDataframe['encoded_message'].tolist())\n",
        "\n",
        "Y = best_model.predict(X_predict, verbose=1)\n",
        "classes = Y.argmax(axis=-1)\n",
        "labels = ['autre', 'mixte', 'negatif', 'positif']\n",
        "class_to_label = lambda t: labels[t]\n",
        "vfunc = vectorize(class_to_label)\n",
        "Y_labels = vfunc(classes)\n",
        "\n",
        "\n",
        "out = './prediction.txt'\n",
        "out_content = ''\n",
        "\n",
        "for i in range(0, len(testTweetsRecord)):\n",
        "    identifier = testTweetsRecord[i]['identifier']\n",
        "    label = Y_labels[i]\n",
        "    line = \"{} {}\\n\".format(identifier, label)\n",
        "    out_content += line\n",
        "\n",
        "save(out, out_content)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                message\n",
            "count   1714                                           \n",
            "unique  1713                                           \n",
            "top     \"Macron c'est la France soumise !\" #2017LeDebat\n",
            "freq    2                                              \n",
            "1714/1714 [==============================] - 1s 362us/step\n",
            "Wrote in ./prediction.txt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}