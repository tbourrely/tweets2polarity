{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_sequentiel--glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiprGXm1pS2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZINcsSiGb5La",
        "colab_type": "code",
        "outputId": "157e09d9-26cc-4dea-f437-45c7cd5c901c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXjuDO-iExk",
        "colab_type": "code",
        "outputId": "31a1689f-7448-4060-9c9d-a600e91695d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install ndjson"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /usr/local/lib/python3.6/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHV3dYucthVU",
        "colab_type": "code",
        "outputId": "58918e2c-d313-447d-af20-2034d5e5e7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import ndjson\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import vectorize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "import nltk\n",
        "# packages settings\n",
        "nltk.data.path.append('./')\n",
        "nltk.download('stopwords', download_dir='./')\n",
        "nltk.download('punkt', download_dir='./')\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to ./...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to ./...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUaFV5ozproJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('french'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YP_TobtD1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadTweetsFromNDJson(filepath):\n",
        "    f = open(filepath)\n",
        "    content = f.read()\n",
        "    return ndjson.loads(content)\n",
        "\n",
        "def save(fileName, content):\n",
        "    f = open(fileName, 'w')\n",
        "    f.write(content)\n",
        "    f.close()\n",
        "    print(\"Wrote in {}\".format(fileName))\n",
        "\n",
        "def setSplitter(complete_dataset, train_quota, validation_quota, test_quota):\n",
        "    splitting_dataset = complete_dataset.copy()\n",
        "\n",
        "    relative_validation_quota = round(validation_quota / (1 - train_quota), 1)\n",
        "    relative_test_quota = round(test_quota / (1 - train_quota - validation_quota), 1)\n",
        "\n",
        "    train_data = splitting_dataset.sample(frac = validation_quota)\n",
        "\n",
        "    # remove training_data from splitting_dataset\n",
        "    splitting_dataset = splitting_dataset.drop(train_data.index)\n",
        "\n",
        "    validation_data = splitting_dataset.sample(frac=relative_validation_quota)\n",
        "\n",
        "    # remove validation_data from splitting_dataset\n",
        "    splitting_dataset = splitting_dataset.drop(validation_data.index)        \n",
        "\n",
        "    test_data = splitting_dataset.sample(frac=relative_test_quota)\n",
        "\n",
        "    return (train_data, validation_data, test_data)\n",
        "\n",
        "def toXY(dataframe_input):\n",
        "    X = ()\n",
        "    Y = ()\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    raw_Y = dataframe_input['polarity']\n",
        "    Y = lb.fit_transform(raw_Y)\n",
        "\n",
        "    print(lb.classes_)\n",
        "\n",
        "    X = dataframe_input.drop(columns=['polarity'])\n",
        "\n",
        "    return (X['encoded_message'].tolist(), Y)\n",
        "\n",
        "def loadGloVe(file_path):\n",
        "    embeddings_index = dict()\n",
        "    f = open(file_path, encoding='utf8')\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "    f.close()\n",
        "    print('Loaded %s word vectors' % len(embeddings_index))\n",
        "\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "def createWeightMatrix(vocab_size, tokenizer, embeddings_index):\n",
        "    embedding_matrix = zeros((vocab_size, 100))\n",
        "    \n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "def removeStopWordsFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([item for item in word_tokenize(x) if item not in stop_words]))\n",
        "    return dataframe\n",
        "\n",
        "def removeVariousTwitterElementsFromMessage(dataframe):\n",
        "    regex_filter = \"(@[a-zA-ZÀ-ÿ0-9]+)|(#[a-zA-ZÀ-ÿ0-9]+)\"\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join(re.sub(regex_filter, ' ', x).split()))\n",
        "    return dataframe\n",
        "\n",
        "def removeUrlsFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: re.split('https?:\\/\\/.*', str(x))[0])\n",
        "    return dataframe\n",
        "\n",
        "def messageStemming(dataframe):\n",
        "    stemmer = FrenchStemmer()\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([stemmer.stem(y) for y in word_tokenize(x)]))\n",
        "    return dataframe\n",
        "\n",
        "def getOnlyAlphaFromMessage(dataframe):\n",
        "    dataframe['message'] = dataframe['message'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.isalpha()]))\n",
        "    return dataframe\n",
        "\n",
        "def prepareDataframeMessage(dataframe_source):\n",
        "    df = dataframe_source.copy()\n",
        "    return (df\n",
        "            .pipe(removeUrlsFromMessage)\n",
        "            .pipe(removeVariousTwitterElementsFromMessage)\n",
        "            .pipe(getOnlyAlphaFromMessage)\n",
        "            .pipe(removeStopWordsFromMessage)\n",
        "            .pipe(messageStemming)\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHWCB7OHlh2",
        "colab_type": "code",
        "outputId": "9765e745-604a-415e-8783-5c60a396e7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load tweets from json (ndjson)\n",
        "tweetsRecord = loadTweetsFromNDJson('./drive/My Drive/Cours/application_innovation/datasets/project_annotated-hashtags-textblob.json')\n",
        "#tweetsRecord = loadTweetsFromNDJson('./project_svm_annotated.json')\n",
        "\n",
        "# load tweets in pandas dataframe\n",
        "tweetsDataframe = pd.DataFrame(tweetsRecord)\n",
        "# filter columns to use only message and polarity\n",
        "tweetsDataframe = tweetsDataframe[['message', 'polarity']]\n",
        "\n",
        "print(tweetsDataframe.head())\n",
        "print(tweetsDataframe.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                                       message polarity\n",
            "0  #2017LeDebat C'était un suicide prémédité par peur du pouvoir et des responsabilités, ou Le pen est juste une cruche vide ?                  negatif\n",
            "1  ET L'ÉCOLOGIE ? #2017LeDebat                                                                                                                 autre  \n",
            "2  Conclusion du journaliste : \"Madame LePen, vous ne respectez même pas les règles que vous avez vous-même fixées\". Tout est dit #2017LeDebat  positif\n",
            "3  \"Et là Marine s'est écroulée comme une merde\" #2017LeDebat  #debat2017  #2017LeDébat  #LeGrandDebat … https://t.co/Pk9LWRmZmF                negatif\n",
            "4  Ces élections c'est une grosse mascarade en fait, un vieux monde a l'agonnie qui fait tout pour survivre #2017LeDebat #rendeznousmelenchon   positif\n",
            "                                                                                                                                             message polarity\n",
            "count   70277                                                                                                                                         70277  \n",
            "unique  43441                                                                                                                                         4      \n",
            "top     \"En parlant constamment de similarité entre prog FN & de la #FI , vous journalistes faites la campagne de M Lepen\" @RaquelGarridoFI #LeDebat  positif\n",
            "freq    19                                                                                                                                            26439  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqSO5YVd0ws8",
        "colab_type": "code",
        "outputId": "e218eac0-0966-4f5d-cb34-3406eae42937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tweetsDataframe = prepareDataframeMessage(tweetsDataframe)\n",
        "tweetsDataframe.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>suicid prémed peur pouvoir respons pen just cruch vid</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>autre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conclus journal madam lepen respect regl fix tout dit</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>là marin écroul comm merd</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>élect gross mascarad fait vieux mond a fait tout survivr</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    message polarity\n",
              "0  suicid prémed peur pouvoir respons pen just cruch vid     negatif\n",
              "1                                                            autre  \n",
              "2  conclus journal madam lepen respect regl fix tout dit     positif\n",
              "3  là marin écroul comm merd                                 negatif\n",
              "4  élect gross mascarad fait vieux mond a fait tout survivr  positif"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUHnrvpckaZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras text tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(tweetsDataframe['message'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOufv8bx_EB",
        "colab_type": "code",
        "outputId": "84f8fd49-9453-4656-f550-7bc9bddf153c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "longest_message_length = tweetsDataframe.message.str.len().max()\n",
        "#words_list = Counter()\n",
        "#tweetsDataframe['message'].str.lower().str.split().apply(words_list.update)\n",
        "\n",
        "#vocab_size = len(words_list.items())\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "labels_size = len(tweetsDataframe['polarity'].unique())\n",
        "print(\"Labels count : {}\".format(labels_size))\n",
        "print(\"Longest message length : {}\".format(longest_message_length))\n",
        "print(\"Vocabulary size : {}\".format(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels count : 4\n",
            "Longest message length : 111\n",
            "Vocabulary size : 14572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZ0wT4plCea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_messages_list = tokenizer.texts_to_sequences(tweetsDataframe['message'].tolist())\n",
        "padded_messages_list = pad_sequences(\n",
        "    encoded_messages_list, \n",
        "    maxlen=longest_message_length, \n",
        "    padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-az1GGllZol",
        "colab_type": "code",
        "outputId": "07fcd1ac-f2c1-473c-e240-27ca70d5303e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = loadGloVe('./drive/My Drive/Cours/application_innovation/glove.6B.100d.txt')\n",
        "embeddings_matrix = createWeightMatrix(vocab_size, tokenizer, embeddings_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeDQykJrzC2h",
        "colab_type": "code",
        "outputId": "c57eda0f-cf1b-42ab-8c20-1e9933f2d563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# encode message column\n",
        "# tweetsDataframe['encoded_message'] = tweetsDataframe['message'].apply(lambda x: one_hot(x, vocab_size))\n",
        "# tweetsDataframe['encoded_message'] = pad_sequences(tweetsDataframe['encoded_message'], maxlen=longest_message_length, padding='post').tolist()\n",
        "\n",
        "tweetsDataframe['encoded_message'] = array(padded_messages_list).tolist()\n",
        "\n",
        "tweetsDataframe = tweetsDataframe.drop(columns=['message'])\n",
        "\n",
        "tweetsDataframe.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>encoded_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negatif</td>\n",
              "      <td>[559, 9645, 141, 234, 572, 7, 70, 3660, 135, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>autre</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positif</td>\n",
              "      <td>[82, 80, 51, 3, 94, 517, 1731, 13, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negatif</td>\n",
              "      <td>[55, 6, 3661, 22, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positif</td>\n",
              "      <td>[274, 250, 1809, 9, 1068, 108, 2, 9, 13, 5055, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  polarity                                                                                                                                                                                                                                                                                                                     encoded_message\n",
              "0  negatif  [559, 9645, 141, 234, 572, 7, 70, 3660, 135, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "1  autre    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]                 \n",
              "2  positif  [82, 80, 51, 3, 94, 517, 1731, 13, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]      \n",
              "3  negatif  [55, 6, 3661, 22, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]           \n",
              "4  positif  [274, 250, 1809, 9, 1068, 108, 2, 9, 13, 5055, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...] "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjJXhz8LqA4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the set\n",
        "\n",
        "# 70% for training\n",
        "training_set_percentage = 0.7\n",
        "# 15% for validation\n",
        "validation_set_percentage = 0.15\n",
        "# 15% for evaluation\n",
        "evaluation_set_percentage = 0.15\n",
        "\n",
        "(training_set, validation_set, evaluation_set) = setSplitter(\n",
        "    tweetsDataframe, \n",
        "    training_set_percentage, \n",
        "    validation_set_percentage,\n",
        "    evaluation_set_percentage\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHu3UEKardOn",
        "colab_type": "code",
        "outputId": "20c96cdf-1f00-4702-e057-4303f538a80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Transform dataframe to X and Y values, to feed to the network\n",
        "(X_training_set, Y_training_set) = toXY(training_set)\n",
        "(X_validation_set, Y_validation_set) = toXY(validation_set)\n",
        "(x_evaluation_set, Y_evaluation_set) = toXY(evaluation_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['autre' 'mixte' 'negatif' 'positif']\n",
            "['autre' 'mixte' 'negatif' 'positif']\n",
            "['autre' 'mixte' 'negatif' 'positif']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyisBHrH6BZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_training_set = array(X_training_set)\n",
        "X_validation_set = array(X_validation_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zxnW2tRPh",
        "colab_type": "code",
        "outputId": "5eb73899-35d6-4d9b-e12b-689347f1a056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "    vocab_size, \n",
        "    100, \n",
        "    input_length=longest_message_length,\n",
        "    weights=[embeddings_matrix],\n",
        "    trainable=False))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(labels_size, activation='relu'))\n",
        "model.add(Dense(labels_size, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP81FuJ6PMh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ModelCheckPoint configuration\n",
        "MODEL_SAVE_PATH = './sequential.hdf5'\n",
        "modelCheckpointCallback = ModelCheckpoint(\n",
        "    MODEL_SAVE_PATH,\n",
        "    monitor='val_categorical_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='max',\n",
        "    period=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcQcNmpVueft",
        "colab_type": "code",
        "outputId": "e36751d6-598d-4eff-da01-155f36eba939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[categorical_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 111, 100)          1457200   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 11100)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 44404     \n",
            "=================================================================\n",
            "Total params: 1,501,604\n",
            "Trainable params: 44,404\n",
            "Non-trainable params: 1,457,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEVs3JOtufi3",
        "colab_type": "code",
        "outputId": "c9af47dd-776f-46f8-9b22-761357e6339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(\n",
        "    X_training_set, \n",
        "    Y_training_set, \n",
        "    epochs=10, \n",
        "    verbose=1, \n",
        "    validation_data=(X_validation_set, Y_validation_set),\n",
        "    callbacks=[modelCheckpointCallback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 10542 samples, validate on 29868 samples\n",
            "Epoch 1/10\n",
            "10542/10542 [==============================] - 3s 271us/step - loss: 1.0791 - categorical_accuracy: 0.4988 - val_loss: 1.0159 - val_categorical_accuracy: 0.5353\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.53529, saving model to ./sequential.hdf5\n",
            "Epoch 2/10\n",
            "10542/10542 [==============================] - 3s 261us/step - loss: 0.9496 - categorical_accuracy: 0.5804 - val_loss: 0.9794 - val_categorical_accuracy: 0.5537\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.53529 to 0.55370, saving model to ./sequential.hdf5\n",
            "Epoch 3/10\n",
            "10542/10542 [==============================] - 3s 266us/step - loss: 0.9000 - categorical_accuracy: 0.6098 - val_loss: 0.9686 - val_categorical_accuracy: 0.5565\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.55370 to 0.55648, saving model to ./sequential.hdf5\n",
            "Epoch 4/10\n",
            "10542/10542 [==============================] - 3s 267us/step - loss: 0.8719 - categorical_accuracy: 0.6264 - val_loss: 0.9610 - val_categorical_accuracy: 0.5643\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.55648 to 0.56428, saving model to ./sequential.hdf5\n",
            "Epoch 5/10\n",
            "10542/10542 [==============================] - 3s 261us/step - loss: 0.8513 - categorical_accuracy: 0.6406 - val_loss: 0.9588 - val_categorical_accuracy: 0.5702\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy improved from 0.56428 to 0.57024, saving model to ./sequential.hdf5\n",
            "Epoch 6/10\n",
            "10542/10542 [==============================] - 3s 259us/step - loss: 0.8361 - categorical_accuracy: 0.6426 - val_loss: 0.9597 - val_categorical_accuracy: 0.5704\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy improved from 0.57024 to 0.57044, saving model to ./sequential.hdf5\n",
            "Epoch 7/10\n",
            "10542/10542 [==============================] - 3s 260us/step - loss: 0.8241 - categorical_accuracy: 0.6467 - val_loss: 0.9630 - val_categorical_accuracy: 0.5716\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy improved from 0.57044 to 0.57158, saving model to ./sequential.hdf5\n",
            "Epoch 8/10\n",
            "10542/10542 [==============================] - 3s 263us/step - loss: 0.8149 - categorical_accuracy: 0.6551 - val_loss: 0.9636 - val_categorical_accuracy: 0.5745\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy improved from 0.57158 to 0.57446, saving model to ./sequential.hdf5\n",
            "Epoch 9/10\n",
            "10542/10542 [==============================] - 3s 271us/step - loss: 0.8074 - categorical_accuracy: 0.6577 - val_loss: 0.9658 - val_categorical_accuracy: 0.5752\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy improved from 0.57446 to 0.57516, saving model to ./sequential.hdf5\n",
            "Epoch 10/10\n",
            "10542/10542 [==============================] - 3s 267us/step - loss: 0.8011 - categorical_accuracy: 0.6579 - val_loss: 0.9705 - val_categorical_accuracy: 0.5760\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.57516 to 0.57603, saving model to ./sequential.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9882980748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsPfpTwPvFTa",
        "colab_type": "code",
        "outputId": "c2999b33-a625-4a6b-c5b9-78653aa8e01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(X_validation_set, Y_validation_set, verbose=1)\n",
        "print(\"Loss : {}\".format(loss))\n",
        "print(\"Accuracy : {}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29868/29868 [==============================] - 1s 44us/step\n",
            "Loss : 0.9704706542332584\n",
            "Accuracy : 0.5760345520209449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWCZR1WxqpFX",
        "colab_type": "code",
        "outputId": "fbc17c64-cc2b-4740-d5d3-8215cee769db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# ----------------------\n",
        "# Predict on test data\n",
        "# ----------------------\n",
        "# --- Use same tokenizer than model\n",
        "\n",
        "# load tweets from json (ndjson)\n",
        "testTweetsRecord = loadTweetsFromNDJson('./drive/My Drive/Cours/application_innovation/datasets/test-euapv.json')\n",
        "\n",
        "# load tweets in pandas dataframe\n",
        "testDataframe = pd.DataFrame(testTweetsRecord)\n",
        "\n",
        "# filter columns to use only message\n",
        "testDataframe = testDataframe[['message']]\n",
        "\n",
        "print(testDataframe.describe())\n",
        "\n",
        "testDataframe = prepareDataframeMessage(testDataframe)\n",
        "\n",
        "# Encode messages using previously fitted tokenizer\n",
        "encoded_messages_list = tokenizer.texts_to_sequences(testDataframe['message'].tolist())\n",
        "padded_messages_list = pad_sequences(\n",
        "    encoded_messages_list, \n",
        "    maxlen=longest_message_length, \n",
        "    padding='post')\n",
        "\n",
        "# Set new column in dataframe with endoded date\n",
        "testDataframe['encoded_message'] = array(padded_messages_list).tolist()\n",
        "\n",
        "testDataframe = testDataframe.drop(columns=['message'])\n",
        "\n",
        "# Use encoded data from pandas dataframe\n",
        "X_predict = array(testDataframe['encoded_message'].tolist())\n",
        "\n",
        "Y = model.predict(X_predict, verbose=1)\n",
        "classes = Y.argmax(axis=-1)\n",
        "labels = ['mixte', 'negatif', 'autre', 'positif'] # from tweets_cnn.ipnyb (model training)\n",
        "class_to_label = lambda t: labels[t]\n",
        "vfunc = vectorize(class_to_label)\n",
        "Y_labels = vfunc(classes)\n",
        "\n",
        "\n",
        "out = './prediction.txt'\n",
        "out_content = ''\n",
        "\n",
        "for i in range(0, len(testTweetsRecord)):\n",
        "    identifier = testTweetsRecord[i]['identifier']\n",
        "    label = Y_labels[i]\n",
        "    line = \"{} {}\\n\".format(identifier, label)\n",
        "    out_content += line\n",
        "\n",
        "save(out, out_content)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                message\n",
            "count   1714                                           \n",
            "unique  1713                                           \n",
            "top     \"Macron c'est la France soumise !\" #2017LeDebat\n",
            "freq    2                                              \n",
            "1714/1714 [==============================] - 0s 53us/step\n",
            "Wrote in ./prediction.txt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}